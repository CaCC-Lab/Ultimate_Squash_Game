"""
Ultimate Squash Game ãƒãƒ³ãƒ‰ãƒ«ã‚µã‚¤ã‚ºæœ€é©åŒ–ãƒ„ãƒ¼ãƒ«
Phase 3A: ãƒãƒ³ãƒ‰ãƒ«ã‚µã‚¤ã‚ºæœ€é©åŒ–

ä¸»ãªæœ€é©åŒ–:
1. Pythonã‚³ãƒ¼ãƒ‰ã®åœ§ç¸®ãƒ»ãƒŸãƒ‹ãƒ•ã‚¡ã‚¤
2. ä¸è¦ãªã‚¤ãƒ³ãƒãƒ¼ãƒˆã®å‰Šé™¤
3. ãƒ‡ãƒƒãƒ‰ã‚³ãƒ¼ãƒ‰é™¤å»
4. HTML/JavaScriptçµ±åˆæœ€é©åŒ–
5. ä¾å­˜é–¢ä¿‚ã®æœ€é©åŒ–
"""
import os
import re
import json
import gzip
import base64
import shutil
from typing import Dict, List, Tuple, Set
from pathlib import Path
import ast
import subprocess


class BundleSizeOptimizer:
    """ãƒãƒ³ãƒ‰ãƒ«ã‚µã‚¤ã‚ºæœ€é©åŒ–ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, project_root: str = "."):
        self.project_root = Path(project_root)
        self.src_dir = self.project_root / "src"
        self.output_dir = self.project_root / "dist"
        self.optimization_report = {
            'original_sizes': {},
            'optimized_sizes': {},
            'savings': {},
            'removed_items': {
                'imports': [],
                'functions': [],
                'classes': [],
                'comments': 0,
                'docstrings': 0
            },
            'bundle_info': {}
        }
        
    def analyze_bundle_size(self) -> Dict:
        """ç¾åœ¨ã®ãƒãƒ³ãƒ‰ãƒ«ã‚µã‚¤ã‚ºã‚’åˆ†æ"""
        print("ğŸ“Š ãƒãƒ³ãƒ‰ãƒ«ã‚µã‚¤ã‚ºåˆ†æé–‹å§‹...")
        
        # Pythonã‚³ãƒ¼ãƒ‰ã‚µã‚¤ã‚º
        python_files = list(self.src_dir.rglob("*.py"))
        total_python_size = 0
        python_details = {}
        
        for file in python_files:
            size = file.stat().st_size
            total_python_size += size
            python_details[str(file.relative_to(self.project_root))] = size
            
        # HTMLãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º
        html_files = list(self.project_root.glob("*.html"))
        total_html_size = 0
        html_details = {}
        
        for file in html_files:
            size = file.stat().st_size
            total_html_size += size
            html_details[file.name] = size
            
        # åˆ†æçµæœ
        analysis = {
            'python': {
                'total_size': total_python_size,
                'file_count': len(python_files),
                'files': python_details
            },
            'html': {
                'total_size': total_html_size,
                'file_count': len(html_files),
                'files': html_details
            },
            'total_size': total_python_size + total_html_size
        }
        
        self.optimization_report['original_sizes'] = analysis
        
        print(f"âœ… åˆ†æå®Œäº†:")
        print(f"  - Pythonã‚³ãƒ¼ãƒ‰: {total_python_size:,} bytes ({len(python_files)} files)")
        print(f"  - HTMLãƒ•ã‚¡ã‚¤ãƒ«: {total_html_size:,} bytes ({len(html_files)} files)")
        print(f"  - åˆè¨ˆ: {analysis['total_size']:,} bytes")
        
        return analysis
    
    def optimize_python_code(self):
        """Pythonã‚³ãƒ¼ãƒ‰ã®æœ€é©åŒ–"""
        print("\nğŸ”§ Pythonã‚³ãƒ¼ãƒ‰æœ€é©åŒ–é–‹å§‹...")
        
        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        optimized_src = self.output_dir / "src"
        optimized_src.mkdir(parents=True, exist_ok=True)
        
        for py_file in self.src_dir.rglob("*.py"):
            relative_path = py_file.relative_to(self.src_dir)
            output_file = optimized_src / relative_path
            output_file.parent.mkdir(parents=True, exist_ok=True)
            
            # ã‚³ãƒ¼ãƒ‰æœ€é©åŒ–
            optimized_code = self._optimize_single_file(py_file)
            
            # æœ€é©åŒ–ã•ã‚ŒãŸã‚³ãƒ¼ãƒ‰ã‚’ä¿å­˜
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(optimized_code)
                
            # ã‚µã‚¤ã‚ºæ¯”è¼ƒ
            original_size = py_file.stat().st_size
            optimized_size = len(optimized_code.encode('utf-8'))
            
            self.optimization_report['optimized_sizes'][str(relative_path)] = {
                'original': original_size,
                'optimized': optimized_size,
                'reduction': original_size - optimized_size,
                'percentage': ((original_size - optimized_size) / original_size * 100) if original_size > 0 else 0
            }
            
            reduction_pct = ((original_size - optimized_size) / original_size * 100) if original_size > 0 else 0
            print(f"  âœ… {relative_path}: {original_size} â†’ {optimized_size} bytes "
                  f"(-{reduction_pct:.1f}%)")
    
    def _optimize_single_file(self, file_path: Path) -> str:
        """å˜ä¸€ã®Pythonãƒ•ã‚¡ã‚¤ãƒ«ã‚’æœ€é©åŒ–"""
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
            
        try:
            # ASTãƒ‘ãƒ¼ã‚¹ã—ã¦æœ€é©åŒ–
            tree = ast.parse(content)
            
            # ä¸è¦ãªã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’æ¤œå‡ºãƒ»å‰Šé™¤
            tree = self._remove_unused_imports(tree, content)
            
            # ä¸è¦ãªdocstringã‚’å‰Šé™¤ï¼ˆæœ¬ç•ªç’°å¢ƒç”¨ï¼‰
            tree = self._remove_docstrings(tree)
            
            # ãƒ‡ãƒƒãƒ‰ã‚³ãƒ¼ãƒ‰ã‚’å‰Šé™¤
            tree = self._remove_dead_code(tree)
            
            # æœ€é©åŒ–ã•ã‚ŒãŸã‚³ãƒ¼ãƒ‰ã‚’ç”Ÿæˆ
            optimized_code = ast.unparse(tree)
            
            # ã‚³ãƒ¡ãƒ³ãƒˆã‚’å‰Šé™¤
            optimized_code = self._remove_comments(optimized_code)
            
            # ä½™åˆ†ãªç©ºç™½ã‚’å‰Šé™¤
            optimized_code = self._minimize_whitespace(optimized_code)
            
            return optimized_code
            
        except Exception as e:
            print(f"    âš ï¸ æœ€é©åŒ–ã‚¨ãƒ©ãƒ¼ ({file_path}): {e}")
            # ã‚¨ãƒ©ãƒ¼æ™‚ã¯å…ƒã®ã‚³ãƒ¼ãƒ‰ã‚’è¿”ã™
            return content
    
    def _remove_unused_imports(self, tree: ast.AST, original_code: str) -> ast.AST:
        """ä½¿ç”¨ã•ã‚Œã¦ã„ãªã„ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’å‰Šé™¤"""
        # ä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹åå‰ã‚’åé›†
        used_names = set()
        
        class NameCollector(ast.NodeVisitor):
            def visit_Name(self, node):
                used_names.add(node.id)
            def visit_Attribute(self, node):
                if isinstance(node.value, ast.Name):
                    used_names.add(node.value.id)
                
        collector = NameCollector()
        collector.visit(tree)
        
        # ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’æœ€é©åŒ–
        new_body = []
        for node in tree.body:
            if isinstance(node, ast.Import):
                # importæ–‡ã®å‡¦ç†
                new_names = []
                for alias in node.names:
                    name = alias.asname or alias.name
                    if name in used_names or name.split('.')[0] in used_names:
                        new_names.append(alias)
                    else:
                        self.optimization_report['removed_items']['imports'].append(name)
                        
                if new_names:
                    node.names = new_names
                    new_body.append(node)
                    
            elif isinstance(node, ast.ImportFrom):
                # from ... importæ–‡ã®å‡¦ç†
                new_names = []
                for alias in node.names:
                    name = alias.asname or alias.name
                    if name in used_names:
                        new_names.append(alias)
                    else:
                        self.optimization_report['removed_items']['imports'].append(f"{node.module}.{name}")
                        
                if new_names:
                    node.names = new_names
                    new_body.append(node)
            else:
                new_body.append(node)
                
        tree.body = new_body
        return tree
    
    def _remove_docstrings(self, tree: ast.AST) -> ast.AST:
        """docstringã‚’å‰Šé™¤ï¼ˆæœ¬ç•ªç’°å¢ƒç”¨ï¼‰"""
        class DocstringRemover(ast.NodeTransformer):
            def visit_FunctionDef(self, node):
                # é–¢æ•°ã®docstringã‚’å‰Šé™¤
                if (node.body and 
                    isinstance(node.body[0], ast.Expr) and 
                    isinstance(node.body[0].value, ast.Constant) and
                    isinstance(node.body[0].value.value, str)):
                    node.body = node.body[1:]
                    self.optimization_report['removed_items']['docstrings'] += 1
                return self.generic_visit(node)
                
            def visit_ClassDef(self, node):
                # ã‚¯ãƒ©ã‚¹ã®docstringã‚’å‰Šé™¤
                if (node.body and 
                    isinstance(node.body[0], ast.Expr) and 
                    isinstance(node.body[0].value, ast.Constant) and
                    isinstance(node.body[0].value.value, str)):
                    node.body = node.body[1:]
                    self.optimization_report['removed_items']['docstrings'] += 1
                return self.generic_visit(node)
                
            def visit_Module(self, node):
                # ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®docstringã‚’å‰Šé™¤
                if (node.body and 
                    isinstance(node.body[0], ast.Expr) and 
                    isinstance(node.body[0].value, ast.Constant) and
                    isinstance(node.body[0].value.value, str)):
                    node.body = node.body[1:]
                    self.optimization_report['removed_items']['docstrings'] += 1
                return self.generic_visit(node)
                
        remover = DocstringRemover()
        tree = remover.visit(tree)
        return tree
    
    def _remove_dead_code(self, tree: ast.AST) -> ast.AST:
        """ãƒ‡ãƒƒãƒ‰ã‚³ãƒ¼ãƒ‰ã‚’å‰Šé™¤"""
        # ç°¡å˜ãªå®Ÿè£…: if __name__ == "__main__": ãƒ–ãƒ­ãƒƒã‚¯ã‚’å‰Šé™¤
        new_body = []
        for node in tree.body:
            if isinstance(node, ast.If):
                # if __name__ == "__main__": ã®æ¤œå‡º
                if (isinstance(node.test, ast.Compare) and
                    isinstance(node.test.left, ast.Name) and
                    node.test.left.id == "__name__" and
                    len(node.test.comparators) == 1 and
                    isinstance(node.test.comparators[0], ast.Constant) and
                    node.test.comparators[0].value == "__main__"):
                    # ãƒ¡ã‚¤ãƒ³ãƒ–ãƒ­ãƒƒã‚¯ã¯å‰Šé™¤
                    continue
            new_body.append(node)
            
        tree.body = new_body
        return tree
    
    def _remove_comments(self, code: str) -> str:
        """ã‚³ãƒ¡ãƒ³ãƒˆã‚’å‰Šé™¤"""
        lines = code.split('\n')
        new_lines = []
        
        for line in lines:
            # ã‚¤ãƒ³ãƒ©ã‚¤ãƒ³ã‚³ãƒ¡ãƒ³ãƒˆã‚’å‰Šé™¤
            if '#' in line:
                # æ–‡å­—åˆ—å†…ã®#ã¯å‰Šé™¤ã—ãªã„
                in_string = False
                quote_char = None
                new_line = []
                
                i = 0
                while i < len(line):
                    char = line[i]
                    
                    if char in ('"', "'") and (i == 0 or line[i-1] != '\\'):
                        if not in_string:
                            in_string = True
                            quote_char = char
                        elif char == quote_char:
                            in_string = False
                            
                    if char == '#' and not in_string:
                        # ã‚³ãƒ¡ãƒ³ãƒˆé–‹å§‹
                        self.optimization_report['removed_items']['comments'] += 1
                        break
                        
                    new_line.append(char)
                    i += 1
                    
                line = ''.join(new_line).rstrip()
                
            if line:  # ç©ºè¡Œã¯é™¤ã
                new_lines.append(line)
                
        return '\n'.join(new_lines)
    
    def _minimize_whitespace(self, code: str) -> str:
        """ä½™åˆ†ãªç©ºç™½ã‚’æœ€å°åŒ–"""
        # è¤‡æ•°ã®ç©ºè¡Œã‚’1ã¤ã«
        code = re.sub(r'\n\s*\n\s*\n', '\n\n', code)
        
        # è¡Œæœ«ã®ç©ºç™½ã‚’å‰Šé™¤
        lines = [line.rstrip() for line in code.split('\n')]
        
        return '\n'.join(lines)
    
    def create_optimized_bundle(self):
        """æœ€é©åŒ–ã•ã‚ŒãŸãƒãƒ³ãƒ‰ãƒ«ã‚’ä½œæˆ"""
        print("\nğŸ“¦ ãƒãƒ³ãƒ‰ãƒ«ä½œæˆé–‹å§‹...")
        
        # Pyodideç”¨ã®çµ±åˆHTMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
        self._create_integrated_html()
        
        # åœ§ç¸®ãƒãƒ³ãƒ‰ãƒ«ã®ä½œæˆ
        self._create_compressed_bundle()
        
        print("âœ… ãƒãƒ³ãƒ‰ãƒ«ä½œæˆå®Œäº†")
    
    def _create_integrated_html(self):
        """Pythonã‚³ãƒ¼ãƒ‰ã‚’çµ±åˆã—ãŸHTMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ"""
        # ãƒ™ãƒ¼ã‚¹ã¨ãªã‚‹HTMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
        base_html = self.project_root / "pyodide_game_demo.html"
        
        if not base_html.exists():
            print("  âš ï¸ ãƒ™ãƒ¼ã‚¹HTMLãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return
            
        with open(base_html, 'r', encoding='utf-8') as f:
            html_content = f.read()
            
        # æœ€é©åŒ–ã•ã‚ŒãŸPythonã‚³ãƒ¼ãƒ‰ã‚’èª­ã¿è¾¼ã¿
        python_modules = {}
        optimized_src = self.output_dir / "src"
        
        for py_file in optimized_src.rglob("*.py"):
            module_path = py_file.relative_to(optimized_src).with_suffix('')
            module_name = str(module_path).replace(os.sep, '.')
            
            with open(py_file, 'r', encoding='utf-8') as f:
                python_modules[module_name] = f.read()
                
        # Pythonã‚³ãƒ¼ãƒ‰ã‚’åŸ‹ã‚è¾¼ã¿
        modules_json = json.dumps(python_modules, ensure_ascii=False)
        
        # HTMLã«åŸ‹ã‚è¾¼ã‚€ãŸã‚ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’ç”Ÿæˆ
        embed_script = f"""
<script>
// æœ€é©åŒ–ã•ã‚ŒãŸPythonãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
const OPTIMIZED_PYTHON_MODULES = {modules_json};

// PyodideåˆæœŸåŒ–æ™‚ã«ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰
async function loadOptimizedModules(pyodide) {{
    for (const [moduleName, moduleCode] of Object.entries(OPTIMIZED_PYTHON_MODULES)) {{
        const path = moduleName.replace(/\\./g, '/') + '.py';
        pyodide.FS.writeFile('/home/pyodide/' + path, moduleCode);
    }}
}}
</script>
"""
        
        # HTMLã«åŸ‹ã‚è¾¼ã¿
        # </head>ã‚¿ã‚°ã®å‰ã«æŒ¿å…¥
        insert_pos = html_content.find('</head>')
        if insert_pos != -1:
            html_content = html_content[:insert_pos] + embed_script + html_content[insert_pos:]
            
        # æœ€é©åŒ–ã•ã‚ŒãŸHTMLã‚’ä¿å­˜
        output_html = self.output_dir / "optimized_game.html"
        with open(output_html, 'w', encoding='utf-8') as f:
            f.write(html_content)
            
        # ã‚µã‚¤ã‚ºæƒ…å ±ã‚’è¨˜éŒ²
        original_size = base_html.stat().st_size
        optimized_size = len(html_content.encode('utf-8'))
        
        self.optimization_report['bundle_info']['integrated_html'] = {
            'file': str(output_html),
            'original_size': original_size,
            'optimized_size': optimized_size,
            'embedded_modules': len(python_modules)
        }
        
        print(f"  âœ… çµ±åˆHTMLä½œæˆ: {output_html}")
        print(f"     ã‚µã‚¤ã‚º: {optimized_size:,} bytes ({len(python_modules)} modules embedded)")
    
    def _create_compressed_bundle(self):
        """åœ§ç¸®ã•ã‚ŒãŸãƒãƒ³ãƒ‰ãƒ«ã‚’ä½œæˆ"""
        # distãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå…¨ä½“ã‚’åœ§ç¸®
        bundle_name = "ultimate_squash_bundle"
        
        # tar.gzå½¢å¼ã§åœ§ç¸®
        shutil.make_archive(
            base_name=str(self.output_dir / bundle_name),
            format='gztar',
            root_dir=str(self.output_dir)
        )
        
        bundle_file = self.output_dir / f"{bundle_name}.tar.gz"
        bundle_size = bundle_file.stat().st_size
        
        # ZIPå½¢å¼ã§ã‚‚ä½œæˆï¼ˆäº’æ›æ€§ã®ãŸã‚ï¼‰
        shutil.make_archive(
            base_name=str(self.output_dir / bundle_name),
            format='zip',
            root_dir=str(self.output_dir)
        )
        
        zip_file = self.output_dir / f"{bundle_name}.zip"
        zip_size = zip_file.stat().st_size
        
        self.optimization_report['bundle_info']['compressed'] = {
            'tar_gz': {
                'file': str(bundle_file),
                'size': bundle_size
            },
            'zip': {
                'file': str(zip_file),
                'size': zip_size
            }
        }
        
        print(f"  âœ… åœ§ç¸®ãƒãƒ³ãƒ‰ãƒ«ä½œæˆ:")
        print(f"     - tar.gz: {bundle_size:,} bytes")
        print(f"     - zip: {zip_size:,} bytes")
    
    def generate_size_report(self):
        """ã‚µã‚¤ã‚ºæœ€é©åŒ–ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        print("\nğŸ“Š æœ€é©åŒ–ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ...")
        
        # ç·å‰Šæ¸›é‡ã‚’è¨ˆç®—
        total_original = 0
        total_optimized = 0
        
        for file_info in self.optimization_report['optimized_sizes'].values():
            total_original += file_info['original']
            total_optimized += file_info['optimized']
            
        total_reduction = total_original - total_optimized
        reduction_percentage = (total_reduction / total_original * 100) if total_original > 0 else 0
        
        # ãƒ¬ãƒãƒ¼ãƒˆä½œæˆ
        report = f"""# ãƒãƒ³ãƒ‰ãƒ«ã‚µã‚¤ã‚ºæœ€é©åŒ–ãƒ¬ãƒãƒ¼ãƒˆ

## å®Ÿæ–½æ—¥æ™‚
{self._get_timestamp()}

## ã‚µãƒãƒªãƒ¼

### å…¨ä½“çš„ãªå‰Šæ¸›åŠ¹æœ
- **å…ƒã®ã‚µã‚¤ã‚º**: {total_original:,} bytes
- **æœ€é©åŒ–å¾Œ**: {total_optimized:,} bytes
- **å‰Šæ¸›é‡**: {total_reduction:,} bytes
- **å‰Šæ¸›ç‡**: {reduction_percentage:.1f}%

### å‰Šé™¤ã•ã‚ŒãŸè¦ç´ 
- **ä¸è¦ãªã‚¤ãƒ³ãƒãƒ¼ãƒˆ**: {len(self.optimization_report['removed_items']['imports'])}å€‹
- **docstring**: {self.optimization_report['removed_items']['docstrings']}å€‹
- **ã‚³ãƒ¡ãƒ³ãƒˆ**: {self.optimization_report['removed_items']['comments']}è¡Œ

## ãƒ•ã‚¡ã‚¤ãƒ«åˆ¥ã®æœ€é©åŒ–çµæœ

| ãƒ•ã‚¡ã‚¤ãƒ« | å…ƒã®ã‚µã‚¤ã‚º | æœ€é©åŒ–å¾Œ | å‰Šæ¸›é‡ | å‰Šæ¸›ç‡ |
|---------|-----------|---------|--------|--------|
"""
        
        # ãƒ•ã‚¡ã‚¤ãƒ«åˆ¥ã®è©³ç´°ã‚’è¿½åŠ 
        for file_path, info in sorted(self.optimization_report['optimized_sizes'].items()):
            report += f"| {file_path} | {info['original']:,} | {info['optimized']:,} | "
            report += f"{info['reduction']:,} | {info['percentage']:.1f}% |\n"
            
        # ãƒãƒ³ãƒ‰ãƒ«æƒ…å ±ã‚’è¿½åŠ 
        if 'bundle_info' in self.optimization_report:
            report += "\n## ç”Ÿæˆã•ã‚ŒãŸãƒãƒ³ãƒ‰ãƒ«\n\n"
            
            if 'integrated_html' in self.optimization_report['bundle_info']:
                html_info = self.optimization_report['bundle_info']['integrated_html']
                report += f"### çµ±åˆHTMLãƒ•ã‚¡ã‚¤ãƒ«\n"
                report += f"- **ãƒ•ã‚¡ã‚¤ãƒ«**: {html_info['file']}\n"
                report += f"- **ã‚µã‚¤ã‚º**: {html_info['optimized_size']:,} bytes\n"
                report += f"- **åŸ‹ã‚è¾¼ã¿ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«æ•°**: {html_info['embedded_modules']}\n\n"
                
            if 'compressed' in self.optimization_report['bundle_info']:
                compressed = self.optimization_report['bundle_info']['compressed']
                report += f"### åœ§ç¸®ãƒãƒ³ãƒ‰ãƒ«\n"
                report += f"- **tar.gz**: {compressed['tar_gz']['size']:,} bytes\n"
                report += f"- **zip**: {compressed['zip']['size']:,} bytes\n"
        
        # æ¨å¥¨äº‹é …ã‚’è¿½åŠ 
        report += self._generate_recommendations()
        
        # ãƒ¬ãƒãƒ¼ãƒˆã‚’ä¿å­˜
        report_file = self.project_root / "BUNDLE_SIZE_OPTIMIZATION_REPORT.md"
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report)
            
        print(f"âœ… ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå®Œäº†: {report_file}")
        
        return report
    
    def _generate_recommendations(self) -> str:
        """æœ€é©åŒ–ã®æ¨å¥¨äº‹é …ã‚’ç”Ÿæˆ"""
        recommendations = "\n## æ¨å¥¨äº‹é …\n\n"
        
        reduction_percentage = 0
        if self.optimization_report['optimized_sizes']:
            total_original = sum(info['original'] for info in self.optimization_report['optimized_sizes'].values())
            total_optimized = sum(info['optimized'] for info in self.optimization_report['optimized_sizes'].values())
            reduction_percentage = ((total_original - total_optimized) / total_original * 100) if total_original > 0 else 0
        
        if reduction_percentage < 10:
            recommendations += "### ã‚³ãƒ¼ãƒ‰ã¯æ—¢ã«æœ€é©åŒ–ã•ã‚Œã¦ã„ã¾ã™\n"
            recommendations += "- ç¾åœ¨ã®ã‚³ãƒ¼ãƒ‰ã¯åŠ¹ç‡çš„ã«æ›¸ã‹ã‚Œã¦ã„ã¾ã™\n"
            recommendations += "- è¿½åŠ ã®æœ€é©åŒ–ã¯é™å®šçš„ãªåŠ¹æœã—ã‹æœŸå¾…ã§ãã¾ã›ã‚“\n\n"
        else:
            recommendations += "### ã•ã‚‰ãªã‚‹æœ€é©åŒ–ã®ä½™åœ°\n"
            
            if len(self.optimization_report['removed_items']['imports']) > 10:
                recommendations += "- **ã‚¤ãƒ³ãƒãƒ¼ãƒˆæœ€é©åŒ–**: å¤šãã®æœªä½¿ç”¨ã‚¤ãƒ³ãƒãƒ¼ãƒˆãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ\n"
                recommendations += "  - å®šæœŸçš„ãªã‚³ãƒ¼ãƒ‰ãƒ¬ãƒ“ãƒ¥ãƒ¼ã§ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’æ•´ç†ã—ã¦ãã ã•ã„\n\n"
                
            if self.optimization_report['removed_items']['docstrings'] > 20:
                recommendations += "- **ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç®¡ç†**: å¤šãã®docstringãŒå‰Šé™¤ã•ã‚Œã¾ã—ãŸ\n"
                recommendations += "  - é–‹ç™ºç‰ˆã¨æœ¬ç•ªç‰ˆã§ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ç®¡ç†ã‚’åˆ†é›¢ã™ã‚‹ã“ã¨ã‚’æ¤œè¨ã—ã¦ãã ã•ã„\n\n"
                
        recommendations += "### Webé…ä¿¡ã®æœ€é©åŒ–\n"
        recommendations += "- **CDNåˆ©ç”¨**: é™çš„ãƒ•ã‚¡ã‚¤ãƒ«ã¯CDNã‹ã‚‰é…ä¿¡\n"
        recommendations += "- **gzipåœ§ç¸®**: ã‚µãƒ¼ãƒãƒ¼ãƒ¬ãƒ™ãƒ«ã§gzipåœ§ç¸®ã‚’æœ‰åŠ¹åŒ–\n"
        recommendations += "- **ã‚­ãƒ£ãƒƒã‚·ãƒ¥è¨­å®š**: é©åˆ‡ãªCache-Controlãƒ˜ãƒƒãƒ€ãƒ¼ã‚’è¨­å®š\n"
        recommendations += "- **é…å»¶èª­ã¿è¾¼ã¿**: å¿…è¦ã«ãªã‚‹ã¾ã§ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®èª­ã¿è¾¼ã¿ã‚’é…å»¶\n\n"
        
        recommendations += "### Pyodideå›ºæœ‰ã®æœ€é©åŒ–\n"
        recommendations += "- **è»½é‡ãªPyodideãƒ“ãƒ«ãƒ‰**: å¿…è¦ãªæ©Ÿèƒ½ã®ã¿ã‚’å«ã‚€ã‚«ã‚¹ã‚¿ãƒ ãƒ“ãƒ«ãƒ‰\n"
        recommendations += "- **WebAssemblyã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°**: instantiateStreamingã‚’ä½¿ç”¨\n"
        recommendations += "- **ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®äº‹å‰ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«**: .pycãƒ•ã‚¡ã‚¤ãƒ«ã®åˆ©ç”¨\n"
        
        return recommendations
    
    def _get_timestamp(self) -> str:
        """ç¾åœ¨ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’å–å¾—"""
        from datetime import datetime
        return datetime.now().strftime("%Y-%m-%d %H:%M:%S")


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("ğŸš€ Ultimate Squash Game ãƒãƒ³ãƒ‰ãƒ«ã‚µã‚¤ã‚ºæœ€é©åŒ–")
    print("=" * 50)
    
    optimizer = BundleSizeOptimizer()
    
    # 1. ç¾åœ¨ã®ãƒãƒ³ãƒ‰ãƒ«ã‚µã‚¤ã‚ºåˆ†æ
    optimizer.analyze_bundle_size()
    
    # 2. Pythonã‚³ãƒ¼ãƒ‰ã®æœ€é©åŒ–
    optimizer.optimize_python_code()
    
    # 3. æœ€é©åŒ–ã•ã‚ŒãŸãƒãƒ³ãƒ‰ãƒ«ã®ä½œæˆ
    optimizer.create_optimized_bundle()
    
    # 4. ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    report = optimizer.generate_size_report()
    
    print("\n" + "=" * 50)
    print("âœ… ãƒãƒ³ãƒ‰ãƒ«ã‚µã‚¤ã‚ºæœ€é©åŒ–å®Œäº†ï¼")
    
    # ç°¡å˜ãªã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º
    if optimizer.optimization_report['optimized_sizes']:
        total_original = sum(info['original'] for info in optimizer.optimization_report['optimized_sizes'].values())
        total_optimized = sum(info['optimized'] for info in optimizer.optimization_report['optimized_sizes'].values())
        total_reduction = total_original - total_optimized
        reduction_percentage = (total_reduction / total_original * 100) if total_original > 0 else 0
        
        print(f"\nğŸ“‰ æœ€é©åŒ–çµæœ:")
        print(f"  å…ƒã®ã‚µã‚¤ã‚º: {total_original:,} bytes")
        print(f"  æœ€é©åŒ–å¾Œ: {total_optimized:,} bytes")
        print(f"  å‰Šæ¸›: {total_reduction:,} bytes ({reduction_percentage:.1f}%)")


if __name__ == "__main__":
    main()